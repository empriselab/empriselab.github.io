---
permalink: /research/
layout: page
title: Research
---

<h2><a href=https://emprise.cs.cornell.edu/rcareworld/ > RCareWorld</a></h2>

<p>
  We present RCareWorld, a human-centric simulation world for physical and social 
  robotic caregiving designed with inputs from stakeholders, such as care-recipients, 
  caregivers, occupational therapists, and roboticists. RCareWorld has realistic
   human models of care recipients with mobility limitations and caregivers, home 
   environments with multiple levels of accessibility and assistive devices, and 
   robots commonly used for caregiving. It interfaces with various physics engines 
   to model diverse material types necessary for simulating caregiving scenarios, 
   and provides the capability to plan, control, and learn both human and robot 
   control policies by integrating with state-of-the-art external planning and 
   learning libraries, and VR devices. We propose a set of realistic caregiving 
   tasks in RCareWorld as a benchmark for physical robotic caregiving and provide 
   baseline control policies for them. We illustrate the high-fidelity simulation 
   capabilities of RCareWorld by 1) demonstrating the execution of a policy learnt 
   in simulation for one of these tasks on a real-world robot setup and 2) receiving 
   positive feedback from clinical stakeholders on the realism of the modeled human 
   avatars and assistive environments for caregiving activities. Additionally, we 
   perform a real-world social robotic caregiving experiment using behaviors modeled 
   in RCareWorld. Robotic caregiving, though potentially impactful towards enhancing 
   the quality of life of care recipients and caregivers, is a field with many 
   barriers to entry due to its interdisciplinary facets. Through this project, 
   we are taking the first step towards building a realistic simulation world for 
   robotic caregiving (RCareWorld) that would enable researchers worldwide to 
   contribute to this impactful field.</p>

<div class="col embed-responsive embed-responsive-16by9">
  <iframe
    class="embed-responsive-item"
    src="https://www.youtube.com/embed/5KLGrvrPjMc"
    title="RCareWorld"
    allowfullscreen
  ></iframe>
</div>


<h2>
  <a href=https://emprise.cs.cornell.edu/hrcom/ > Human-Robot Commensality </a>
  </h2>

<p>
  Being able to eat independently with friends and family is considered one of 
  the most memorable and important activities for people with mobility 
  limitations. Robots can potentially help with this activity but robot-assisted 
  feeding is a multi-faceted problem with challenges in bite acquisition, bite 
  timing, and bite transfer. Bite timing in particular becomes uniquely 
  challenging in social dining scenarios due to the possibility of interrupting 
  a social human-robot group interaction during commensality. Through this project
  we are developing bite timing strategies that take into account the delicate balance of 
  social cues can lead to seamless interactions during robot-assisted feeding in 
  a social dining scenario.
</p>

<div class="col embed-responsive embed-responsive-16by9">
  <iframe
    class="embed-responsive-item"
    src="https://www.youtube.com/embed/mNy1cloWrP0"
    title="Human-Robot Commensality"
    allowfullscreen
  ></iframe>
</div>

<br />


<h2>Robot-assisted Feeding</h2>

<p>
  Eating is an activity of daily living (ADL) and losing the ability to
  self-feed can be devastating. Robots have the potential to help with these
  tasks. Successful robotic assistive feeding depends on reliable bite
  acquisition, appropriate bite timing, and easy bite transfer in both
  individual and social dining settings. Automating bite acquisition is daunting
  as the universe of foods, cutlery, and human strategies is massive and the
  activity demands robust nonprehensile manipulation of a deformable
  hard-to-model target. Bite timing, especially in social dining settings, is a
  delicate dance of multimodal signaling (via gaze, facial expressions,
  gestures, and speech, to name a few), action, and sometimes coercion. Bite
  transfer constitutes a unique type of robot-human handover where the human
  needs to use the mouth. Through this project, we are developing algorithms and
  technologies that can address these challenges towards a robotic system that
  can autonomously feed people with upper-extremity mobility limitations in real
  homes.
</p>

<div class="col embed-responsive embed-responsive-16by9">
  <iframe
    class="embed-responsive-item"
    src="https://www.youtube.com/embed/CJ66x7JfqG0"
    title="Caregiving Robots at Cornell"
    allowfullscreen
  ></iframe>
</div>

<br />

<!-- <h2>RCareWorld</h2>

<p>Coming soon</p>

<div class="col embed-responsive embed-responsive-16by9"></div>

<br />

<h2>SPARCS</h2>

<p>Coming soon</p>

<div class="col embed-responsive embed-responsive-16by9"></div>

<br />

<h2>Human-Robot Commensality</h2>

<p>Coming soon</p>

<div class="col embed-responsive embed-responsive-16by9"></div>

<br /> -->

<h2>Compliant Manipulation with Whole-arm Sensing</h2>

<p>
  Physical interactions between robots and humans are inevitable and desired
  during caregiving. Tactile sensing can enable a robot to infer properties of
  its surroundings from planned and incidental contact during manipulation in
  unstructured human environments. Through this project, we are developing
  solutions that can efficiently combine multimodal sensing and perception to
  develop intelligent planning and control policies for safe and efficient
  manipulation with and around humans.
</p>

<div class="col embed-responsive embed-responsive-16by9">
  <iframe
    class="embed-responsive-item"
    src="https://www.youtube.com/embed/beDPwv56WeE"
    allowfullscreen
  ></iframe>
</div>

<br />

<h2>Featured Videos</h2>

<div class="row row-cols-3">
  {% for video in site.data.vidlist %}
  <div class="col my-3">
    <div class="embed-responsive embed-responsive-16by9">
      <iframe
        class="embed-responsive-item"
        src="https://www.youtube.com/embed/{{ video.ytid }}"
        allowfullscreen
      ></iframe>
    </div>
  </div>
  {% endfor %}
</div>
